{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de71e55-09ee-4b36-904c-8213b1b38d39",
   "metadata": {},
   "source": [
    "# Importing Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf9d1af-6638-408a-9cec-574d7a2b91e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryanjadon/miniconda3/envs/recommendations_experiments/lib/python3.10/site-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.10.13 (main, Sep 11 2023, 08:16:02) [Clang 14.0.6 ]\n",
      "Spark version: 3.5.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import FloatType, IntegerType, LongType, StructType, StructField\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import HashingTF, CountVectorizer, VectorAssembler\n",
    "import warnings\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.spark_splitters import spark_random_split\n",
    "from recommenders.evaluation.spark_evaluation import SparkDiversityEvaluation\n",
    "from recommenders.utils.spark_utils import start_or_get_spark\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Spark version: {}\".format(pyspark.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b6770b-c5f9-4753-9eec-ef3212af48c0",
   "metadata": {},
   "source": [
    "## Spark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141caf03-1d7a-4965-bae4-246d35fdaf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "# user, item column names\n",
    "COL_USER=\"UserId\"\n",
    "COL_ITEM=\"MovieId\"\n",
    "COL_RATING=\"Rating\"\n",
    "COL_TITLE=\"Title\"\n",
    "COL_GENRE=\"Genre\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41b683e3-ad9b-43c2-80e3-caae957c2d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/26 16:46:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# setting up spark\n",
    "spark = start_or_get_spark(\"ALS PySpark\", memory=\"16g\")\n",
    "spark.conf.set(\"spark.sql.analyzer.failAmbiguousSelfJoin\", \"false\")\n",
    "spark.conf.set(\"spark.sql.crossJoin.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dd004f-1948-47dc-8dd3-5ee0caa35f6d",
   "metadata": {},
   "source": [
    "# Diversity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f21557ad-900a-4ae1-b01f-5eabbefd6239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diversity_results(diversity_eval):\n",
    "    metrics = {\n",
    "        \"catalog_coverage\":diversity_eval.catalog_coverage(),\n",
    "        \"distributional_coverage\":diversity_eval.distributional_coverage(), \n",
    "        \"novelty\": diversity_eval.novelty(), \n",
    "        \"diversity\": diversity_eval.diversity(), \n",
    "        \"serendipity\": diversity_eval.serendipity()\n",
    "    }\n",
    "    return metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea0b7bc3-3c1e-462f-b608-5a4b62f9bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens_data_sizes = [\"100k\", \"1m\", \"10m\", \"20m\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81a3a90-2a94-47ed-ad3c-ce98bbcc519c",
   "metadata": {},
   "source": [
    "# ALS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "452e5f27-563c-4cd2-87ec-05e5785ccdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\n",
    "    \"userCol\": COL_USER,\n",
    "    \"itemCol\": COL_ITEM,\n",
    "    \"ratingCol\": COL_RATING,\n",
    "}\n",
    "\n",
    "\n",
    "als = ALS(\n",
    "    rank=10,\n",
    "    maxIter=15,\n",
    "    implicitPrefs=False,\n",
    "    regParam=0.05,\n",
    "    coldStartStrategy='drop',\n",
    "    nonnegative=False,\n",
    "    seed=42,\n",
    "    **header\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84262af3-d1d8-4269-8df1-73ca80beac26",
   "metadata": {},
   "source": [
    "# Experiment on MOVIE LENS 100K Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f544754-b1a4-4dc8-9d43-ac6a5762018b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 194k/194k [00:09<00:00, 20.4kKB/s]\n",
      "23/11/26 16:46:58 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "|MovieId|UserId|Rating| Timestamp|               Title|               Genre|\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "|     29|     1|   3.5|1112484676|City of Lost Chil...|Adventure|Drama|F...|\n",
      "|   2529|     3|   5.0| 945175680|Planet of the Ape...| Action|Drama|Sci-Fi|\n",
      "|   2529|     7|   4.0|1011206732|Planet of the Ape...| Action|Drama|Sci-Fi|\n",
      "|   2529|    10|   3.0| 943497376|Planet of the Ape...| Action|Drama|Sci-Fi|\n",
      "|    474|    13|   4.0| 849082697|In the Line of Fi...|     Action|Thriller|\n",
      "|    474|    15|   4.0| 840207465|In the Line of Fi...|     Action|Thriller|\n",
      "|  45726|    18|   2.5|1236293298|You, Me and Dupre...|              Comedy|\n",
      "|    474|    20|   2.0|1126539515|In the Line of Fi...|     Action|Thriller|\n",
      "|    474|    21|   4.0| 992189970|In the Line of Fi...|     Action|Thriller|\n",
      "|    474|    22|   3.0| 994638573|In the Line of Fi...|     Action|Thriller|\n",
      "|     29|    27|   3.0|1112243971|City of Lost Chil...|Adventure|Drama|F...|\n",
      "|  60756|    31|   0.5|1424735773|Step Brothers (2008)|              Comedy|\n",
      "|  71530|    31|   3.0|1424733696|   Surrogates (2009)|Action|Sci-Fi|Thr...|\n",
      "|    474|    32|   4.0| 845962792|In the Line of Fi...|     Action|Thriller|\n",
      "|    474|    34|   4.0| 846509385|In the Line of Fi...|     Action|Thriller|\n",
      "|   3764|    44|   4.0|1038250225|F/X2 (a.k.a. F/X ...|Action|Crime|Thri...|\n",
      "|     29|    53|   5.0| 938947097|City of Lost Chil...|Adventure|Drama|F...|\n",
      "|    474|    54|   4.0| 974836300|In the Line of Fi...|     Action|Thriller|\n",
      "|   1950|    54|   3.0| 974905861|In the Heat of th...|       Drama|Mystery|\n",
      "|   2529|    54|   4.0| 974905914|Planet of the Ape...| Action|Drama|Sci-Fi|\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MOVIELENS_DATA_SIZE = \"20m\"\n",
    "\n",
    "schema = StructType(\n",
    "(\n",
    "    StructField(COL_USER, IntegerType()),\n",
    "    StructField(COL_ITEM, IntegerType()),\n",
    "    StructField(COL_RATING, FloatType()),\n",
    "    StructField(\"Timestamp\", LongType()),\n",
    ")\n",
    ")\n",
    "\n",
    "data = movielens.load_spark_df(spark, size=MOVIELENS_DATA_SIZE, schema=schema, title_col=COL_TITLE, genres_col=COL_GENRE)\n",
    "data.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aa62eb-b33d-404b-b7c8-e31f879f7230",
   "metadata": {},
   "source": [
    "### Split the data using the Spark random splitter provided in utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f8f3d3-b944-4351-bda2-15bdb9d6f852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N train_df 14998529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N test_df 5001734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df, test_df = spark_random_split(data.select(COL_USER, COL_ITEM, COL_RATING), ratio=0.75, seed=123)\n",
    "print (\"N train_df\", train_df.cache().count())\n",
    "print (\"N test_df\", test_df.cache().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606dd8d6-9aeb-49d5-bbbe-e771dda70d38",
   "metadata": {},
   "source": [
    "### Get all possible user-item pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6caa9a6a-8a29-4e69-a9e6-b087e5ddf4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = train_df.select(COL_USER).distinct()\n",
    "items = train_df.select(COL_ITEM).distinct()\n",
    "user_item = users.crossJoin(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544379dd-bf71-4368-9428-60ed1d93e03e",
   "metadata": {},
   "source": [
    "### Train the ALS model on the training data, and get the top-k recommendations for our testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631a477a-82ee-40fd-8062-0d041f0ebc36",
   "metadata": {},
   "source": [
    "To predict movie ratings, we use the rating data in the training set as users' explicit feedback. The hyperparameters used in building the model are referenced from here. We do not constrain the latent factors (nonnegative = False) in order to allow for both positive and negative preferences towards movies. Timing will vary depending on the machine being used to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bc3082-70c1-447b-b475-dad65bef85f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/26 16:47:17 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/11/26 16:47:17 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "23/11/26 16:47:17 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 16.946659542001726 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model = als.fit(train_df)\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f97a3ca-e8e3-4e3b-b36a-77ae9f610059",
   "metadata": {},
   "source": [
    "In the movie recommendation use case, recommending movies that have been rated by the users does not make sense. Therefore, the rated movies are removed from the recommended items.\n",
    "In order to achieve this, we recommend all movies to all users, and then remove the user-movie pairs that exist in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a8e755d-dfe7-4d12-83a9-9ebde31244ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/26 16:47:28 WARN Column: Constructing trivially true equals predicate, 'UserId#6 = UserId#6'. Perhaps you need to use aliases.\n",
      "ERROR:root:KeyboardInterrupt while sending command.              (16 + 8) / 200]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aryanjadon/miniconda3/envs/recommendations_experiments/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/aryanjadon/miniconda3/envs/recommendations_experiments/lib/python3.10/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/Users/aryanjadon/miniconda3/envs/recommendations_experiments/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m\n\u001b[1;32m      5\u001b[0m dfs_pred_exclude_train \u001b[38;5;241m=\u001b[39m dfs_pred\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m      6\u001b[0m     train_df\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      7\u001b[0m     (dfs_pred[COL_USER] \u001b[38;5;241m==\u001b[39m train_df[COL_USER]) \u001b[38;5;241m&\u001b[39m (dfs_pred[COL_ITEM] \u001b[38;5;241m==\u001b[39m train_df[COL_ITEM]),\n\u001b[1;32m      8\u001b[0m     how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m top_all \u001b[38;5;241m=\u001b[39m dfs_pred_exclude_train\u001b[38;5;241m.\u001b[39mfilter(dfs_pred_exclude_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.Rating\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misNull()) \\\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m COL_USER, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m COL_ITEM, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtop_all\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m window \u001b[38;5;241m=\u001b[39m Window\u001b[38;5;241m.\u001b[39mpartitionBy(COL_USER)\u001b[38;5;241m.\u001b[39morderBy(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdesc())    \n\u001b[1;32m     17\u001b[0m top_k_reco \u001b[38;5;241m=\u001b[39m top_all\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m, F\u001b[38;5;241m.\u001b[39mrow_number()\u001b[38;5;241m.\u001b[39mover(window)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mfilter(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m TOP_K)\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/recommendations_experiments/lib/python3.10/site-packages/pyspark/sql/dataframe.py:1234\u001b[0m, in \u001b[0;36mDataFrame.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the number of rows in this :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \n\u001b[1;32m   1214\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;124;03m    3\u001b[39;00m\n\u001b[1;32m   1233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/recommendations_experiments/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/miniconda3/envs/recommendations_experiments/lib/python3.10/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/miniconda3/envs/recommendations_experiments/lib/python3.10/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/recommendations_experiments/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Score all user-item pairs\n",
    "dfs_pred = model.transform(user_item)\n",
    "\n",
    "# Remove seen items.\n",
    "dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n",
    "    train_df.alias(\"train\"),\n",
    "    (dfs_pred[COL_USER] == train_df[COL_USER]) & (dfs_pred[COL_ITEM] == train_df[COL_ITEM]),\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "top_all = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[\"train.Rating\"].isNull()) \\\n",
    "    .select('pred.' + COL_USER, 'pred.' + COL_ITEM, 'pred.' + \"prediction\")\n",
    "\n",
    "print(top_all.count())\n",
    "    \n",
    "window = Window.partitionBy(COL_USER).orderBy(F.col(\"prediction\").desc())    \n",
    "top_k_reco = top_all.select(\"*\", F.row_number().over(window).alias(\"rank\")).filter(F.col(\"rank\") <= TOP_K).drop(\"rank\")\n",
    " \n",
    "print(top_k_reco.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c642f5c8-f77c-4347-954b-af370bd720da",
   "metadata": {},
   "source": [
    "### Performance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044812a-ea66-4e22-9592-77742f87dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_diversity_eval = SparkDiversityEvaluation(\n",
    "    train_df = train_df, \n",
    "    reco_df = top_k_reco,\n",
    "    col_user = COL_USER, \n",
    "    col_item = COL_ITEM\n",
    ")\n",
    "\n",
    "als_diversity_metrics = get_diversity_results(als_diversity_eval)\n",
    "als_diversity_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa575a4-96c5-44e5-a162-85e750806b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c92ac35-0b90-47c2-aeaf-c66f702c0e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommendations_experiments",
   "language": "python",
   "name": "recommendations_experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
