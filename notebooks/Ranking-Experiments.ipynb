{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ccaea93-2003-4327-98cf-9e33472f0597",
   "metadata": {},
   "source": [
    "# Importing Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f88900e6-409c-4279-a6ca-3ea632789da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a5c117e-fdf4-411e-9742-1fc547fe7200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FM model is only supported on Linux.\n",
      "Windows executable can be found at http://www.libfm.org.\n",
      "System version: 3.10.13 (main, Sep 11 2023, 08:16:02) [Clang 14.0.6 ]\n",
      "Number of cores: 8\n",
      "NumPy version: 1.26.2\n",
      "Pandas version: 2.1.3\n",
      "Surprise version: 1.1.3\n",
      "Cornac version: 1.17\n",
      "PySpark version: 3.5.0\n",
      "CUDA version: None\n",
      "CuDNN version: None\n",
      "TensorFlow version: 2.15.0\n",
      "PyTorch version: 2.1.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scrapbook as sb\n",
    "import surprise\n",
    "import cornac\n",
    "import pyspark\n",
    "# NOTE: TF needs to be imported before PyTorch, otherwise we get an error\n",
    "import tensorflow as tf \n",
    "# only show error messages\n",
    "tf.get_logger().setLevel('ERROR') \n",
    "\n",
    "import torch\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.utils.general_utils import get_number_processors\n",
    "from recommenders.datasets.python_splitters import python_stratified_split\n",
    "from recommenders.utils.spark_utils import start_or_get_spark\n",
    "from recommenders.utils.gpu_utils import get_cuda_version, get_cudnn_version\n",
    "\n",
    "from benchmark_utils import * \n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"Number of cores: {get_number_processors()}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Surprise version: {surprise.__version__}\")\n",
    "print(f\"Cornac version: {cornac.__version__}\")\n",
    "print(f\"PySpark version: {pyspark.__version__}\")\n",
    "print(f\"CUDA version: {get_cuda_version()}\")\n",
    "print(f\"CuDNN version: {get_cudnn_version()}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f554131-b2c4-4996-a638-d6ef058efa57",
   "metadata": {},
   "source": [
    "## Setting Up Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a1eedd3-8808-447c-9419-1a7a78b26890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/26 13:23:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/11/26 13:23:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = start_or_get_spark(\"PySpark\", memory=\"32g\")\n",
    "spark.conf.set(\"spark.sql.analyzer.failAmbiguousSelfJoin\", \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82635f76-8cb7-40fc-ab89-3c7a45812ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds to make sure out runs are reproducible\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a575cbe-6a45-48e1-8b61-2de1cea617e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movielens data size: 100k, 1m, 10m, or 20m\n",
    "data_sizes = [\"100k\",\"1m\",\"10m\",\"20m\"]\n",
    "\n",
    "algorithms = [\"als\", \n",
    "              \"sar\",\n",
    "              \"svd\",\n",
    "              \"ncf\", \n",
    "              \"bpr\", \n",
    "              \"bivae\", \n",
    "              \"lightgcn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1181c1e-8d0e-44dc-8bda-eb19254accd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "environments = {\n",
    "    \"als\": \"pyspark\",\n",
    "    \"sar\": \"python_cpu\",\n",
    "    \"svd\": \"python_cpu\",\n",
    "    \"bpr\": \"python_cpu\",\n",
    "    \"ncf\": \"python_gpu\",\n",
    "    \"bivae\": \"python_gpu\",\n",
    "    \"lightgcn\": \"python_gpu\",\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"als\": [\"ranking\"],\n",
    "    \"sar\": [\"ranking\"],\n",
    "    \"svd\": [\"ranking\"],\n",
    "    \"ncf\": [\"ranking\"],\n",
    "    \"bpr\": [\"ranking\"],\n",
    "    \"bivae\": [\"ranking\"],\n",
    "    \"lightgcn\": [\"ranking\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46b2c7d0-308b-4d8c-ad51-0289d8e60f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_params = {\n",
    "    \"rank\": 10,\n",
    "    \"maxIter\": 20,\n",
    "    \"implicitPrefs\": False,\n",
    "    \"alpha\": 0.1,\n",
    "    \"regParam\": 0.05,\n",
    "    \"coldStartStrategy\": \"drop\",\n",
    "    \"nonnegative\": False,\n",
    "    \"userCol\": DEFAULT_USER_COL,\n",
    "    \"itemCol\": DEFAULT_ITEM_COL,\n",
    "    \"ratingCol\": DEFAULT_RATING_COL,\n",
    "}\n",
    "\n",
    "sar_params = {\n",
    "    \"similarity_type\": \"jaccard\",\n",
    "    \"time_decay_coefficient\": 30,\n",
    "    \"time_now\": None,\n",
    "    \"timedecay_formula\": True,\n",
    "    \"col_user\": DEFAULT_USER_COL,\n",
    "    \"col_item\": DEFAULT_ITEM_COL,\n",
    "    \"col_rating\": DEFAULT_RATING_COL,\n",
    "    \"col_timestamp\": DEFAULT_TIMESTAMP_COL,\n",
    "}\n",
    "\n",
    "svd_params = {\n",
    "    \"n_factors\": 150,\n",
    "    \"n_epochs\": 15,\n",
    "    \"lr_all\": 0.005,\n",
    "    \"reg_all\": 0.02,\n",
    "    \"random_state\": SEED,\n",
    "    \"verbose\": False\n",
    "}\n",
    "\n",
    "ncf_params = {\n",
    "    \"model_type\": \"NeuMF\",\n",
    "    \"n_factors\": 4,\n",
    "    \"layer_sizes\": [16, 8, 4],\n",
    "    \"n_epochs\": 15,\n",
    "    \"batch_size\": 1024,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"verbose\": 10\n",
    "}\n",
    "\n",
    "bpr_params = {\n",
    "    \"k\": 200,\n",
    "    \"max_iter\": 200,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"lambda_reg\": 1e-3,\n",
    "    \"seed\": SEED,\n",
    "    \"verbose\": False\n",
    "}\n",
    "\n",
    "bivae_params = {\n",
    "    \"k\": 100,\n",
    "    \"encoder_structure\": [200],\n",
    "    \"act_fn\": \"tanh\",\n",
    "    \"likelihood\": \"pois\",\n",
    "    \"n_epochs\": 500,\n",
    "    \"batch_size\": 1024,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"seed\": SEED,\n",
    "    \"use_gpu\": True,\n",
    "    \"verbose\": False\n",
    "}\n",
    "\n",
    "lightgcn_param = {\n",
    "    \"model_type\": \"lightgcn\",\n",
    "    \"n_layers\": 3,\n",
    "    \"batch_size\": 1024,\n",
    "    \"embed_size\": 64,\n",
    "    \"decay\": 0.0001,\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"eval_epoch\": 5,\n",
    "    \"top_k\": DEFAULT_K,\n",
    "    \"metrics\": [\"recall\", \"ndcg\", \"precision\", \"map\"],\n",
    "    \"save_model\":False,\n",
    "    \"MODEL_DIR\":\".\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e653a6a-ca90-4ef2-adb5-61e6722800e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"als\": als_params,\n",
    "    \"sar\": sar_params,\n",
    "    \"svd\": svd_params,\n",
    "    \"ncf\": ncf_params,\n",
    "    \"bpr\": bpr_params,\n",
    "    \"bivae\": bivae_params,\n",
    "    \"lightgcn\": lightgcn_param,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6736cb84-b373-412a-ae38-30e2ad56c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_training_data = {\n",
    "    \"als\": prepare_training_als,\n",
    "    \"sar\": prepare_training_sar,\n",
    "    \"svd\": prepare_training_svd,\n",
    "    \"ncf\": prepare_training_ncf,\n",
    "    \"bpr\": prepare_training_cornac,\n",
    "    \"bivae\": prepare_training_cornac,\n",
    "    \"lightgcn\": prepare_training_lightgcn,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea124ae1-cdcc-4bc2-8384-db117a26c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_metrics_data = {\n",
    "    \"als\": lambda train, test: prepare_metrics_als(train, test)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11e8aa21-9ffa-47a3-a8c8-92e6f10f67ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = {\n",
    "    \"als\": lambda params, data: train_als(params, data),\n",
    "    \"sar\": lambda params, data: train_sar(params, data), \n",
    "    \"svd\": lambda params, data: train_svd(params, data),\n",
    "    \"ncf\": lambda params, data: train_ncf(params, data),\n",
    "    \"bpr\": lambda params, data: train_bpr(params, data),\n",
    "    \"bivae\": lambda params, data: train_bivae(params, data),\n",
    "    \"lightgcn\": lambda params, data: train_lightgcn(params, data),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10d60d57-7241-4a7e-b008-faacdb2565d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_predictor = {\n",
    "    \"als\": lambda model, test, train: recommend_k_als(model, test, train),\n",
    "    \"sar\": lambda model, test, train: recommend_k_sar(model, test, train),\n",
    "    \"svd\": lambda model, test, train: recommend_k_svd(model, test, train),\n",
    "    \"ncf\": lambda model, test, train: recommend_k_ncf(model, test, train),\n",
    "    \"bpr\": lambda model, test, train: recommend_k_cornac(model, test, train),\n",
    "    \"bivae\": lambda model, test, train: recommend_k_cornac(model, test, train),\n",
    "    \"lightgcn\": lambda model, test, train: recommend_k_lightgcn(model, test, train),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85320f36-02fd-4a2e-8993-89963f0af9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    " ranking_evaluator = {\n",
    "    \"als\": lambda test, predictions, k: ranking_metrics_pyspark(test, predictions, k),\n",
    "    \"sar\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"svd\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"ncf\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"bpr\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"bivae\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "    \"lightgcn\": lambda test, predictions, k: ranking_metrics_python(test, predictions, k),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdd77e84-9c53-4361-9143-c62fcc2786fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(data, algo, k, train_time, time_ranking, ranking_metrics):\n",
    "    summary = {\"Data\": data, \n",
    "               \"Algo\": algo, \n",
    "               \"K\": k, \n",
    "               \"Train time (s)\": train_time, \n",
    "               \"Predicting time (s)\": time_ranking, \n",
    "               \"Recommending time (s)\": time_ranking}\n",
    "    print(ranking_metrics)\n",
    "    summary.update(ranking_metrics)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf2927a-5bd3-4f72-ab5f-3ab21534a2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Data Size100k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.81k/4.81k [00:00<00:00, 7.80kKB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Movielens 100k: (100000, 4)\n",
      "\n",
      "Computing als algorithm on Movielens 100k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/26 13:23:26 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "23/11/26 13:23:32 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "23/11/26 13:23:34 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/11/26 13:23:34 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "23/11/26 13:23:34 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 12.2488s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/26 13:23:42 WARN Column: Constructing trivially true equals predicate, 'userID#223 = userID#223'. Perhaps you need to use aliases.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking prediction time: 0.3164s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 158:>                                                        (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "algosummary = {}\n",
    "\n",
    "for data_size in data_sizes:\n",
    "    \n",
    "    print(\"Working on Data Size\"+str(data_size))    \n",
    "    \n",
    "    # Load the dataset\n",
    "    df = movielens.load_pandas_df(\n",
    "        size=data_size,\n",
    "        header=[DEFAULT_USER_COL, DEFAULT_ITEM_COL, DEFAULT_RATING_COL, DEFAULT_TIMESTAMP_COL]\n",
    "    )\n",
    "    \n",
    "    print(\"Size of Movielens {}: {}\".format(data_size, df.shape))\n",
    "    \n",
    "    # Split the dataset\n",
    "    df_train, df_test = python_stratified_split(df,\n",
    "                                                ratio=0.75, \n",
    "                                                min_rating=1, \n",
    "                                                filter_by=\"item\", \n",
    "                                                col_user=DEFAULT_USER_COL, \n",
    "                                                col_item=DEFAULT_ITEM_COL\n",
    "                                                )\n",
    "   \n",
    "    # Loop through the algos\n",
    "    for algo in algorithms:\n",
    "        print(f\"\\nComputing {algo} algorithm on Movielens {data_size}\")\n",
    "          \n",
    "        # Data prep for training set\n",
    "        train = prepare_training_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n",
    "        \n",
    "        # Get model parameters\n",
    "        model_params = params[algo]\n",
    "          \n",
    "        # Train the model\n",
    "        model, time_train = trainer[algo](model_params, train)\n",
    "        print(f\"Training time: {time_train}s\")\n",
    "                \n",
    "        # Predict and evaluate\n",
    "        train, test = prepare_metrics_data.get(algo, lambda x,y:(x,y))(df_train, df_test)\n",
    "        \n",
    "        if \"ranking\" in metrics[algo]:\n",
    "            # Predict for ranking\n",
    "            top_k_scores, time_ranking = ranking_predictor[algo](model, test, train)\n",
    "            print(f\"Ranking prediction time: {time_ranking}s\")\n",
    "            \n",
    "            # Evaluate for ranking\n",
    "            rankings = ranking_evaluator[algo](test, top_k_scores, DEFAULT_K)\n",
    "        else:\n",
    "            rankings = None\n",
    "            time_ranking = np.nan\n",
    "            \n",
    "        # Record results\n",
    "        algosummary[algo] = generate_summary(data_size, \n",
    "                                   algo, \n",
    "                                   DEFAULT_K, \n",
    "                                   time_train, \n",
    "                                   time_ranking, \n",
    "                                   rankings)\n",
    "\n",
    "        algosummary[algo][\"F1@K\"]= 2 * (algosummary[algo][\"Precision@k\"] * algosummary[algo][\"Recall@k\"]) / (algosummary[algo][\"Precision@k\"] + algosummary[algo][\"Recall@k\"])\n",
    "\n",
    "        print(\"*\"*100)\n",
    "        print(algosummary)\n",
    "        print(\"*\"*100)\n",
    "\n",
    "    print(\"#\"*100)\n",
    "    print(\"Complete Summary on DataSet\")\n",
    "    print(algosummary)\n",
    "    print(\"#\"*100)\n",
    "        \n",
    "print(\"\\nComputation finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2cb736-ba9c-4d78-928c-91820b459f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each data size and each algorithm, a recommender is evaluated.\n",
    "\n",
    "cols = [\"Data\", \n",
    "        \"Algo\", \n",
    "        \"K\", \n",
    "        \"Train time (s)\", \n",
    "        \"Predicting time (s)\", \n",
    "        \"Recommending time (s)\", \n",
    "        \"MAP\", \n",
    "        \"nDCG@k\", \n",
    "        \"Precision@k\", \n",
    "        \"Recall@k\"]\n",
    "\n",
    "df_results = pd.DataFrame(columns=cols)\n",
    " # df_results.loc[df_results.shape[0] + 1] = summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd772eb5-b883-46a9-95b9-4ebf435554bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommendations_experiments",
   "language": "python",
   "name": "recommendations_experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
